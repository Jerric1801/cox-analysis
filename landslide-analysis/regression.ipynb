{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 10yr: 0.8225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 20yr: 0.8225\n",
      "Accuracy for 50yr: 0.8225\n",
      "Risk level counts for 10yr:\n",
      "Risk_Level\n",
      "Medium    107\n",
      "High       40\n",
      "Low         4\n",
      "Name: count, dtype: int64\n",
      "Risk level counts for 20yr:\n",
      "Risk_Level\n",
      "Medium    107\n",
      "High       40\n",
      "Low         4\n",
      "Name: count, dtype: int64\n",
      "Risk level counts for 50yr:\n",
      "Risk_Level\n",
      "Medium    107\n",
      "High       40\n",
      "Low         4\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import gumbel_r\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"./data/landslide_data_final.csv\")\n",
    "\n",
    "timeframes = [\"10yr\", \"20yr\", \"50yr\"]\n",
    "\n",
    "# Calculate probabilities from Gumbel distribution\n",
    "loc = 10  # Location parameter (adjust if needed)\n",
    "scale = 5  # Scale parameter (adjust if needed)\n",
    "return_periods = [10, 20, 50]  # Corresponding to your timeframes\n",
    "probabilities = [1 - (1 / rp) for rp in return_periods]\n",
    "weights = gumbel_r.pdf(return_periods, loc=loc, scale=scale) * probabilities\n",
    "weights /= weights.sum()  # Normalize weights\n",
    "\n",
    "# Invert the weights to give higher weight to rarer events\n",
    "weights = 1 / weights\n",
    "weights /= weights.sum()  # Re-normalize weights\n",
    "\n",
    "# Create a dictionary mapping timeframes to weights\n",
    "weights_dict = dict(zip(timeframes, weights))\n",
    "\n",
    "for timeframe in timeframes:\n",
    "    df[f\"Flow_accumulation_{timeframe}_multiplied_log\"] *= weights_dict[timeframe]\n",
    "    df[f\"Runoff_{timeframe}\"] *= weights_dict[timeframe]\n",
    "\n",
    "    X = df[\n",
    "        [\n",
    "            f\"Flow_accumulation_{timeframe}_multiplied_log\",\n",
    "            \"Slope_classification\",\n",
    "            \"Flow_direction\",\n",
    "            f\"Runoff_{timeframe}\",\n",
    "            \"Fill_sinks\",\n",
    "            \"Basins\",\n",
    "            \"intersects_buildings\",\n",
    "            \"GLG\",\n",
    "        ]\n",
    "    ]\n",
    "    y = df[\"Landslide_Occurred\"]\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    numeric_features = [\n",
    "        f\"Flow_accumulation_{timeframe}_multiplied_log\",\n",
    "        f\"Runoff_{timeframe}\",\n",
    "        \"Flow_direction\",\n",
    "        \"Fill_sinks\",\n",
    "        \"Basins\",\n",
    "        \"Slope_classification\",\n",
    "        \"intersects_buildings\",\n",
    "    ]\n",
    "    categorical_features = [\"GLG\"]\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    "    )\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit and transform the training data\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "    # Transform the test data\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Create and train the model with hyperparameter tuning\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    param_grid = {\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"penalty\": [\"l1\", \"l2\"],\n",
    "        \"solver\": [\"liblinear\", \"saga\"],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring=\"roc_auc\")\n",
    "    grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test_transformed)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy for {timeframe}: {accuracy:.4f}\")\n",
    "\n",
    "    # Make predictions for the entire dataset\n",
    "    df[f\"Susceptibility_{timeframe}\"] = best_model.predict_proba(\n",
    "        preprocessor.transform(X)\n",
    "    )[:, 1]\n",
    "\n",
    "df[\"Combined_Susceptibility\"] = df[\n",
    "    [f\"Susceptibility_{timeframe}\" for timeframe in timeframes]\n",
    "].mean(axis=1)  # Average the individual susceptibilities\n",
    "\n",
    "# Classify into risk levels based on quantiles of the combined susceptibility\n",
    "low_threshold = df[\"Combined_Susceptibility\"].quantile(0.1)\n",
    "high_threshold = df[\"Combined_Susceptibility\"].quantile(0.9)\n",
    "\n",
    "for timeframe in timeframes:\n",
    "    df_timeframe = df[\n",
    "        [\n",
    "            \"Landslide_ID\",\n",
    "            \"Latitude\",\n",
    "            \"Longitude\",\n",
    "            f\"Susceptibility_{timeframe}\",\n",
    "            \"Combined_Susceptibility\",  # Include for combined risk assessment\n",
    "        ]\n",
    "    ].copy()\n",
    "\n",
    "    # Classify into risk levels using combined susceptibility thresholds\n",
    "    df_timeframe[\"Risk_Level\"] = \"Medium\"\n",
    "    df_timeframe.loc[\n",
    "        df_timeframe[\"Combined_Susceptibility\"] < low_threshold, \"Risk_Level\"\n",
    "    ] = \"Low\"\n",
    "    df_timeframe.loc[\n",
    "        df_timeframe[\"Combined_Susceptibility\"] > high_threshold, \"Risk_Level\"\n",
    "    ] = \"High\"\n",
    "\n",
    "    # Select only the required columns and IDs\n",
    "    df_timeframe = df_timeframe[\n",
    "        (df_timeframe[\"Landslide_ID\"] >= 0) & (df_timeframe[\"Landslide_ID\"] <= 152)\n",
    "    ][\n",
    "        [\n",
    "            \"Landslide_ID\",\n",
    "            \"Latitude\",\n",
    "            \"Longitude\",\n",
    "            f\"Susceptibility_{timeframe}\",\n",
    "            \"Risk_Level\",\n",
    "        ]\n",
    "    ].sort_values(by=\"Landslide_ID\")\n",
    "\n",
    "    # Count risk level values\n",
    "    risk_counts = df_timeframe[\"Risk_Level\"].value_counts()\n",
    "    print(f\"Risk level counts for {timeframe}:\\n{risk_counts}\")\n",
    "\n",
    "    df_timeframe.to_csv(f\"./data/landslide_susceptibility_{timeframe}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8165680473372781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90       139\n",
      "           1       0.33      0.03      0.06        30\n",
      "\n",
      "    accuracy                           0.82       169\n",
      "   macro avg       0.58      0.51      0.48       169\n",
      "weighted avg       0.74      0.82      0.75       169\n",
      "\n",
      "Confusion Matrix:\n",
      " [[137   2]\n",
      " [ 29   1]]\n",
      "AUC: 0.7046762589928058\n",
      "Accuracy: 0.8106508875739645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89       139\n",
      "           1       0.25      0.03      0.06        30\n",
      "\n",
      "    accuracy                           0.81       169\n",
      "   macro avg       0.54      0.51      0.48       169\n",
      "weighted avg       0.72      0.81      0.75       169\n",
      "\n",
      "Confusion Matrix:\n",
      " [[136   3]\n",
      " [ 29   1]]\n",
      "AUC: 0.7182254196642684\n",
      "Accuracy: 0.8224852071005917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90       139\n",
      "           1       0.50      0.03      0.06        30\n",
      "\n",
      "    accuracy                           0.82       169\n",
      "   macro avg       0.66      0.51      0.48       169\n",
      "weighted avg       0.77      0.82      0.75       169\n",
      "\n",
      "Confusion Matrix:\n",
      " [[138   1]\n",
      " [ 29   1]]\n",
      "AUC: 0.7159472422062351\n",
      "Risk level counts for 10yr:\n",
      "Risk_Level\n",
      "High      136\n",
      "Low       135\n",
      "Medium    128\n",
      "Name: count, dtype: int64\n",
      "Risk level counts for 20yr:\n",
      "Risk_Level\n",
      "High      136\n",
      "Low       135\n",
      "Medium    128\n",
      "Name: count, dtype: int64\n",
      "Risk level counts for 50yr:\n",
      "Risk_Level\n",
      "High      136\n",
      "Low       135\n",
      "Medium    128\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import gumbel_r, randint, uniform\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"./data/landslide_data_final.csv\")\n",
    "\n",
    "timeframes = [\"10yr\", \"20yr\", \"50yr\"]\n",
    "\n",
    "# Calculate probabilities from Gumbel distribution\n",
    "loc = 10  # Location parameter (adjust if needed)\n",
    "scale = 5  # Scale parameter (adjust if needed)\n",
    "return_periods = [10, 20, 50]  # Corresponding to your timeframes\n",
    "probabilities = [1 - (1 / rp) for rp in return_periods]\n",
    "weights = gumbel_r.pdf(return_periods, loc=loc, scale=scale) * probabilities\n",
    "weights /= weights.sum()  # Normalize weights\n",
    "\n",
    "# Invert the weights to give higher weight to rarer events\n",
    "weights = 1 / weights\n",
    "weights /= weights.sum()  # Re-normalize weights\n",
    "\n",
    "# Create a dictionary mapping timeframes to weights\n",
    "weights_dict = dict(zip(timeframes, weights))\n",
    "\n",
    "for timeframe in timeframes:\n",
    "    # Scale flow accumulation and runoff based on exponential weights\n",
    "    df[f\"Flow_accumulation_{timeframe}_multiplied_log\"] *= weights_dict[timeframe]\n",
    "    df[f\"Runoff_{timeframe}\"] *= weights_dict[timeframe]\n",
    "\n",
    "    X = df[\n",
    "        [\n",
    "            f\"Flow_accumulation_{timeframe}_multiplied_log\",\n",
    "            \"Slope_classification\",\n",
    "            \"Flow_direction\",\n",
    "            f\"Runoff_{timeframe}\",\n",
    "            \"Fill_sinks\",\n",
    "            \"Basins\",\n",
    "            \"intersects_buildings\",\n",
    "            \"GLG\",\n",
    "        ]\n",
    "    ]\n",
    "    y = df[\"Landslide_Occurred\"]\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    numeric_features = [\n",
    "        f\"Flow_accumulation_{timeframe}_multiplied_log\",\n",
    "        f\"Runoff_{timeframe}\",\n",
    "        \"Flow_direction\",\n",
    "        \"Fill_sinks\",\n",
    "        \"Basins\",\n",
    "    ]\n",
    "    categorical_features = [\"Slope_classification\", \"GLG\"]\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    "    )\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit and transform the training data\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "    # Transform the test data\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Create and train the model with hyperparameter tuning\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    param_grid = {\n",
    "        \"n_estimators\": randint(50, 200),  # Number of trees in random forest\n",
    "        \"max_depth\": randint(3, 15),  # Maximum number of levels in tree\n",
    "        \"min_samples_split\": randint(2, 20),  # Minimum number of samples required to split a node\n",
    "        \"min_samples_leaf\": randint(1, 10),  # Minimum number of samples required at each leaf node\n",
    "        \"max_features\": uniform(0.1, 0.9),  # Number of features to consider at every split\n",
    "        \"bootstrap\": [True, False],  # Method of selecting samples for training each tree\n",
    "    }\n",
    "\n",
    "\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=50,  # Number of parameter settings that are sampled\n",
    "        cv=5,\n",
    "        scoring=\"roc_auc\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "    )\n",
    "    grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(X_test_transformed)\n",
    "    y_prob = best_model.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"AUC:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "    # Make predictions for the entire dataset\n",
    "    df[f\"Susceptibility_{timeframe}\"] = best_model.predict_proba(\n",
    "        preprocessor.transform(X)\n",
    "    )[:, 1]\n",
    "\n",
    "df[\"Combined_Susceptibility\"] = df[\n",
    "    [f\"Susceptibility_{timeframe}\" for timeframe in timeframes]\n",
    "].mean(axis=1)  # Average the individual susceptibilities\n",
    "\n",
    "# Classify into risk levels based on quantiles of the combined susceptibility\n",
    "low_threshold = df[\"Combined_Susceptibility\"].quantile(0.33)\n",
    "high_threshold = df[\"Combined_Susceptibility\"].quantile(0.67)\n",
    "\n",
    "for timeframe in timeframes:\n",
    "    df_timeframe = df[\n",
    "        [\n",
    "            \"Landslide_ID\",\n",
    "            \"Latitude\",\n",
    "            \"Longitude\",\n",
    "            f\"Susceptibility_{timeframe}\",\n",
    "            \"Combined_Susceptibility\",  # Include for combined risk assessment\n",
    "        ]\n",
    "    ].copy()\n",
    "\n",
    "    # Classify into risk levels using combined susceptibility thresholds\n",
    "    df_timeframe[\"Risk_Level\"] = \"Medium\"\n",
    "    df_timeframe.loc[\n",
    "        df_timeframe[\"Combined_Susceptibility\"] < low_threshold, \"Risk_Level\"\n",
    "    ] = \"Low\"\n",
    "    df_timeframe.loc[\n",
    "        df_timeframe[\"Combined_Susceptibility\"] > high_threshold, \"Risk_Level\"\n",
    "    ] = \"High\"\n",
    "\n",
    "    # Select only the required columns and IDs\n",
    "    df_timeframe = df_timeframe[\n",
    "        (df_timeframe[\"Landslide_ID\"] >= 0) & (df_timeframe[\"Landslide_ID\"] <= 400)\n",
    "    ][\n",
    "        [\n",
    "            \"Landslide_ID\",\n",
    "            \"Latitude\",\n",
    "            \"Longitude\",\n",
    "            f\"Susceptibility_{timeframe}\",\n",
    "            \"Risk_Level\",\n",
    "        ]\n",
    "    ].sort_values(by=\"Landslide_ID\")\n",
    "\n",
    "    # Count risk level values\n",
    "    risk_counts = df_timeframe[\"Risk_Level\"].value_counts()\n",
    "    print(f\"Risk level counts for {timeframe}:\\n{risk_counts}\")\n",
    "\n",
    "    df_timeframe.to_csv(f\"./data/landslide_susceptibility_{timeframe}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8225\n",
      "Risk level counts:\n",
      "Risk_Level\n",
      "Medium    84\n",
      "High      56\n",
      "Low       11\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"./data/landslide_data_final.csv\")\n",
    "\n",
    "# Calculate the average flow accumulation and runoff across timeframes\n",
    "df[\"Flow_accumulation_avg\"] = df[\n",
    "    [f\"Flow_accumulation_{timeframe}_multiplied_log\" for timeframe in [\"10yr\", \"20yr\", \"50yr\"]]\n",
    "].mean(axis=1)\n",
    "df[\"Runoff_avg\"] = df[[f\"Runoff_{timeframe}\" for timeframe in [\"10yr\", \"20yr\", \"50yr\"]]].mean(axis=1)\n",
    "\n",
    "# Prepare the feature matrix and target variable\n",
    "X = df[\n",
    "    [\n",
    "        \"Flow_accumulation_avg\",\n",
    "        \"Slope_classification\",\n",
    "        \"Flow_direction\",\n",
    "        \"Runoff_avg\",\n",
    "        \"Fill_sinks\",\n",
    "        \"Basins\",\n",
    "        \"intersects_buildings\",\n",
    "        \"GLG\",\n",
    "    ]\n",
    "]\n",
    "y = df[\"Landslide_Occurred\"]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_features = [\n",
    "    \"Flow_accumulation_avg\",\n",
    "    \"Runoff_avg\",\n",
    "    \"Flow_direction\",\n",
    "    \"Fill_sinks\",\n",
    "    \"Basins\",\n",
    "    \"Slope_classification\",\n",
    "    \"intersects_buildings\",\n",
    "]\n",
    "categorical_features = [\"GLG\"]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Create and train the model with hyperparameter tuning\n",
    "model = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"solver\": [\"liblinear\", \"saga\"],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test_transformed)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Make predictions for the entire dataset\n",
    "df[\"Susceptibility\"] = best_model.predict_proba(preprocessor.transform(X))[:, 1]\n",
    "\n",
    "# Classify into risk levels based on quantiles of the susceptibility\n",
    "low_threshold = df[\"Susceptibility\"].quantile(0.2)\n",
    "high_threshold = df[\"Susceptibility\"].quantile(0.8)\n",
    "\n",
    "df[\"Risk_Level\"] = \"Medium\"\n",
    "df.loc[df[\"Susceptibility\"] < low_threshold, \"Risk_Level\"] = \"Low\"\n",
    "df.loc[df[\"Susceptibility\"] > high_threshold, \"Risk_Level\"] = \"High\"\n",
    "\n",
    "# Select only the required columns and IDs\n",
    "df_output = df[\n",
    "    (df[\"Landslide_ID\"] >= 0) & (df[\"Landslide_ID\"] <= 152)\n",
    "][\n",
    "    [\n",
    "        \"Landslide_ID\",\n",
    "        \"Latitude\",\n",
    "        \"Longitude\",\n",
    "        \"Susceptibility\",\n",
    "        \"Risk_Level\",\n",
    "    ]\n",
    "].sort_values(by=\"Landslide_ID\")\n",
    "\n",
    "# Count risk level values\n",
    "risk_counts = df_output[\"Risk_Level\"].value_counts()\n",
    "print(f\"Risk level counts:\\n{risk_counts}\")\n",
    "\n",
    "df_output.to_csv(f\"./data/landslide_susceptibility.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize  $E[Z] = \\sum_{(i,j) \\in P} \\frac{D_{ij}}{S_{ij} \\cdot (1 - \\max(CR_{ij,flood}(t), CR_{ij,landslide} \\cdot W_{flood-landslide}(t)))}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize  $E[Z] = \\sum_{(i,j) \\in P} \\frac{D_{ij}}{S_{ij} \\cdot (1 - \\max(CR_{ij,flood_{map\\_s}}, CR_{ij,landslide} \\cdot W_{flood-landslide_{map\\_s}}))}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
